{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO8Ga/FPKX39vQWXgSJuyb5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-001.png\" class=\"img-responsive\"/>\n","</div>\n","\n"],"metadata":{"id":"EUZY_VNVJVKT"}},{"cell_type":"code","source":["l = list(range(90, 100))\n","\n","for num in l:\n","    print(num + 5)\n","#print(l)\n","\n","#print(range(5))\n","#print(list(range(5)))\n","\n","def add_five(max_num):\n","    for num in range(max_num):\n","        print(num + '5')\n","\n","add_five(5)"],"metadata":{"id":"3Sj_A8jo8vbE","colab":{"base_uri":"https://localhost:8080/","height":471},"executionInfo":{"status":"error","timestamp":1768934756514,"user_tz":300,"elapsed":12,"user":{"displayName":"William Theisen","userId":"17727777209816459717"}},"outputId":"db4d0175-82ee-4deb-b267-b2950a99e38a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n"]},{"output_type":"error","ename":"TypeError","evalue":"unsupported operand type(s) for +: 'int' and 'str'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-379716175.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0madd_five\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-379716175.py\u001b[0m in \u001b[0;36madd_five\u001b[0;34m(max_num)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_five\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0madd_five\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"]}]},{"cell_type":"markdown","source":["<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-002.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-003.png\" class=\"img-responsive\"/>\n","</div>\n","\n"],"metadata":{"id":"mxAAF5GY8vxw"}},{"cell_type":"code","source":["#print(5 + '5')"],"metadata":{"id":"58YQQupe_7UK","colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"status":"error","timestamp":1768931049389,"user_tz":300,"elapsed":43,"user":{"displayName":"William Theisen","userId":"17727777209816459717"}},"outputId":"4a1ca15f-6fcb-42c2-e8c9-7e8321079f96"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"unsupported operand type(s) for +: 'int' and 'str'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-433515484.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"]}]},{"cell_type":"markdown","source":["<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-004.png\" class=\"img-responsive\"/>\n","</div>"],"metadata":{"id":"mtQM5cbm_6f7"}},{"cell_type":"code","source":["combined = str(5) + '5'\n","print(type(combined))\n","print(combined)"],"metadata":{"id":"BLGTx_tM-IAn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768931136295,"user_tz":300,"elapsed":42,"user":{"displayName":"William Theisen","userId":"17727777209816459717"}},"outputId":"7d839f95-14e0-4a95-f326-8c2d5b886f2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'str'>\n","55\n"]}]},{"cell_type":"markdown","source":["<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-005.png\" class=\"img-responsive\"/>\n","</div>"],"metadata":{"id":"0jUdJ9FmIsfB"}},{"cell_type":"code","source":["def count_consecutive_pairs(nums):\n","    counts = {}\n","\n","    for pair in zip(nums, nums[1:]):\n","        counts[pair] = counts.get(pair, 0) + 1\n","\n","    return counts\n","\n","print(count_consecutive_pairs([1, 2, 3, 1, 2]))\n","\n","for pair in zip([1, 2, 3], [4, 5, 6]):\n","    print(pair)"],"metadata":{"id":"MoxgX40-IuO7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768931715095,"user_tz":300,"elapsed":43,"user":{"displayName":"William Theisen","userId":"17727777209816459717"}},"outputId":"4fe05c37-9ef7-47b1-f32c-645f60f87aca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{(1, 2): 2, (2, 3): 1, (3, 1): 1}\n","(1, 4)\n","(2, 5)\n","(3, 6)\n"]}]},{"cell_type":"markdown","source":["<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-006.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-007.png\" class=\"img-responsive\"/>\n","</div>"],"metadata":{"id":"Fan_E23oGShw"}},{"cell_type":"code","source":["l = ['cats', 'dogs', 'fish', 'birds']\n","\n","#print(l[0])\n","#print(l[0:2])\n","print(l[2:])\n","#print(l[:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3sFj9cA1GS2_","executionInfo":{"status":"ok","timestamp":1768931906450,"user_tz":300,"elapsed":4,"user":{"displayName":"William Theisen","userId":"17727777209816459717"}},"outputId":"6c6c0fc8-7ec3-4431-e786-bc5850c6748f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['fish', 'birds']\n"]}]},{"cell_type":"markdown","source":["<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-008.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-009.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-010.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-011.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-012.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-013.png\" class=\"img-responsive\"/>\n","</div>\n","\n","\n","\n","\n"],"metadata":{"id":"5spfu41pJHGy"}},{"cell_type":"code","source":["import os\n","\n","try:\n","    import google.colab\n","    REPO_URL = \"https://github.com/wtheisen/nd-cse-10124-lectures.git\"\n","\n","    REPO_NAME = \"/content/nd-cse-10124-lectures\"\n","    L_PATH = \"nd-cse-10124-lectures/Datasets\"\n","\n","    %cd /content/\n","    !rm -r {REPO_NAME}\n","\n","    # Clone repo\n","    if not os.path.exists(REPO_NAME):\n","        !git clone {REPO_URL}\n","\n","        # cd into the data folder\n","        %cd {L_PATH}\n","        !pwd\n","\n","except ImportError:\n","    print(\"Unable to download repo, either:\")\n","    print(\"\\tA.) You're not on colab\")\n","    print(\"\\tB.) It has already been cloned\")\n","\n","\n","import utilities as uts"],"metadata":{"id":"XauIb-liOtSM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768931933006,"user_tz":300,"elapsed":1330,"user":{"displayName":"William Theisen","userId":"17727777209816459717"}},"outputId":"590bb686-c698-48fa-e4fc-350a3fe6c630"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'nd-cse-10124-lectures'...\n","remote: Enumerating objects: 111, done.\u001b[K\n","remote: Counting objects: 100% (111/111), done.\u001b[K\n","remote: Compressing objects: 100% (77/77), done.\u001b[K\n","remote: Total 111 (delta 54), reused 89 (delta 32), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (111/111), 17.37 MiB | 42.05 MiB/s, done.\n","Resolving deltas: 100% (54/54), done.\n","/content/nd-cse-10124-lectures/Datasets\n","/content/nd-cse-10124-lectures/Datasets\n"]}]},{"cell_type":"markdown","source":["<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-015.png\" class=\"img-responsive\"/>\n","</div>"],"metadata":{"id":"uK0uNTX6Ypx9"}},{"cell_type":"code","source":["print('Size of Jabberwocky Graph (Words):', len(uts.build_graph_word('jabberwocky.txt')))\n","print('Size of Zoomer Graph (Words):', len(uts.build_graph_word('zoomer.txt')))\n","print('Size of Shakespeare Graph (Words):', len(uts.build_graph_word('shakespeare.txt')))\n","print('#' * 80)\n","print('Size of Jabberwocky Graph (Chars):', len(uts.build_graph_char('jabberwocky.txt')))\n","print('Size of Shakespeare Graph (Chars):', len(uts.build_graph_char('shakespeare.txt')))\n","print('Size of Zoomer Graph (Chars):', len(uts.build_graph_char('zoomer.txt')))\n","print('#' * 80)\n","\n","num_gens = 3\n","\n","word_graph = uts.build_graph_word('zoomer.txt')\n","print('Word Level Generation [zoomer.txt]:')\n","for i in range(0, num_gens):\n","  print(f'\\t{i}: {' '.join(uts.generate_sequence(word_graph, 50))}')\n","\n","print('#' * 80)\n","\n","char_graph = uts.build_graph_char('zoomer.txt')\n","print('Character Level Generation [zoomer.txt]:')\n","for i in range(0, num_gens):\n","  print(f'\\t{i}: {''.join(uts.generate_sequence(char_graph, 50))}')\n"],"metadata":{"id":"QUGJIkSao3om","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768932276360,"user_tz":300,"elapsed":1997,"user":{"displayName":"William Theisen","userId":"17727777209816459717"}},"outputId":"31b62a13-5b02-4871-d0a3-ed4a67f083ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of Jabberwocky Graph (Words): 103\n","Size of Zoomer Graph (Words): 3698\n","Size of Shakespeare Graph (Words): 67506\n","################################################################################\n","Size of Jabberwocky Graph (Chars): 46\n","Size of Shakespeare Graph (Chars): 91\n","Size of Zoomer Graph (Chars): 90\n","################################################################################\n","Word Level Generation [zoomer.txt]:\n","\t0: <SOS> Sorry, ;S, can complain all day, OO! <EOS>\n","\t1: <SOS> That image is too many beers last night! <EOS>\n","\t2: <SOS> Make sure you don’t get your CAM for the good now, take several seats. <EOS>\n","################################################################################\n","Character Level Generation [zoomer.txt]:\n","\t0: <SOS>PChinuriltelaton Thin’t y.<EOS>\n","\t1: <SOS>YSA o ts bu’sodn nsodit sst llere sou, m igouss.<EOS>\n","\t2: <SOS>MURMOYSSNDMWKI’t.<EOS>\n"]}]},{"cell_type":"markdown","source":["\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-014.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-016.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-017.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-018.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture03/slide-019.png\" class=\"img-responsive\"/>\n","</div>"],"metadata":{"id":"-JW9ueYDH-tv"}},{"cell_type":"code","source":["!pip install rustbpe\n","\n","# -----------------------------------------------------------------------------\n","# Tokenizer based on rustbpe + tiktoken combo\n","import rustbpe\n","import tiktoken\n","\n","SPECIAL_TOKENS = [\n","    \"<|sos|>\", # every document begins with the Start of Sequence (SOS) token that delimits documents\n","    \"<|soum|>\", # start of user message\n","    \"<|eoum|>\", # end of user message\n","    \"<|soam|>\", # start of assistant message\n","    \"<|eoam|>\", # end of assistant message\n","]\n","\n","SPLIT_PATTERN = r\"\"\"'(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}+|\\p{N}{1,2}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]|\\s+(?!\\S)|\\s+\"\"\"\n","\n","class RustBPETokenizer:\n","    def __init__(self, enc, bos_token):\n","        self.enc = enc\n","        self.bos_token_id = self.encode_special(bos_token)\n","\n","    @classmethod\n","    def train_from_iterator(cls, text_iterator, vocab_size):\n","        # 1) train using rustbpe\n","        tokenizer = rustbpe.Tokenizer()\n","\n","        # the special tokens are inserted later in __init__, we don't train them here\n","        vocab_size_no_special = vocab_size - len(SPECIAL_TOKENS)\n","        tokenizer.train_from_iterator(text_iterator, vocab_size_no_special, pattern=SPLIT_PATTERN)\n","\n","        # 2) construct the associated tiktoken encoding for inference\n","        pattern = tokenizer.get_pattern()\n","        mergeable_ranks_list = tokenizer.get_mergeable_ranks()\n","        mergeable_ranks = {bytes(k): v for k, v in mergeable_ranks_list}\n","        tokens_offset = len(mergeable_ranks)\n","        special_tokens = {name: tokens_offset + i for i, name in enumerate(SPECIAL_TOKENS)}\n","\n","        enc = tiktoken.Encoding(name=\"rustbpe\", pat_str=pattern, mergeable_ranks=mergeable_ranks, special_tokens=special_tokens)\n","\n","        return cls(enc, \"<|sos|>\")\n","\n","    def encode(self, text):\n","        return self.enc.encode_ordinary(text)\n","\n","    def encode_special(self, text):\n","        return self.enc.encode_single_token(text)\n","\n","    def decode(self, ids):\n","        return self.enc.decode(ids)\n","\n","    def render_conversation(self, conversation, max_tokens=2048):\n","        \"\"\"\n","        Tokenize a single Chat conversation (which we call a \"doc\" or \"document\" here).\n","        Returns:\n","        - ids: list[int] is a list of token ids of this rendered conversation\n","        \"\"\"\n","        messages = conversation[\"messages\"]\n","\n","        # now we can tokenize the conversation\n","        ids = [self.encode_special('<|sos|>')]\n","\n","        for i, message in enumerate(messages):\n","            content = message[\"content\"]\n","\n","            if message[\"role\"] == \"user\":\n","                ids += [self.encode_special('<|soum|>')] + self.encode(content) + [self.encode_special('<|eoum|>')]\n","\n","            elif message[\"role\"] == \"assistant\":\n","                ids += [self.encode_special('<|soam|>')] + self.encode(content) + [self.encode_special('<|eoam|>')]\n","\n","        # truncate to max_tokens tokens MAX (helps prevent OOMs)\n","        ids = ids[:max_tokens]\n","\n","        return ids\n","\n","    def visualize_tokenization(self, ids):\n","        \"\"\"Small helper function useful in debugging: visualize the tokenization of render_conversation\"\"\"\n","        RED = '\\033[91m'\n","        GREEN = '\\033[92m'\n","        RESET = '\\033[0m'\n","        GRAY = '\\033[90m'\n","\n","        tokens = []\n","        for i, token_id in enumerate(ids):\n","            token_str = self.decode([token_id])\n","            tokens.append(f\"{GREEN}{token_str}{GRAY}({token_id}){RESET}\")\n","\n","            if token_str in ['<|sos|>', '<|eoum|>', '<|eoam|>']:\n","                tokens.append('\\n\\n\\t')\n","\n","        return ' | '.join(tokens)"],"metadata":{"id":"nPVeFvJzd7d5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_text = uts.get_file_str('shakespeare.txt')\n","\n","nanochat_tokenizer = RustBPETokenizer.train_from_iterator(training_text, 256 + len(SPECIAL_TOKENS))\n","\n","conversation = {\n","    'messages': [\n","        {'role': 'user', 'content': 'Hello there general kenobi'},\n","        {'role': 'assistant', 'content': 'Hello there grevious'},\n","        {'role': 'user', 'content': 'I love neffer'},\n","    ]\n","}\n","\n","ids = nanochat_tokenizer.render_conversation(conversation)\n","print(nanochat_tokenizer.visualize_tokenization(ids))"],"metadata":{"id":"oO7H8-XJfg84"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Export to HTML\n","\n","Uncomment the final line of the cell below and run it to export this notebook to HTML"],"metadata":{"id":"xSLHa2zwsAlr"}},{"cell_type":"code","source":["import os, json\n","\n","def export_notebook():\n","  L_PATH = \"nd-cse-10124-lectures/Notebooks\"\n","  L = \"Lecture_03_Tokenization\"\n","\n","  try:\n","      from google.colab import _message, files\n","\n","      # where you WANT it to live (repo folder)\n","      repo_ipynb_path = f\"/content/{L_PATH}/{L}.ipynb\"\n","\n","      # grab current notebook contents from the UI\n","      nb = _message.blocking_request(\"get_ipynb\", timeout_sec=1)[\"ipynb\"]\n","\n","      # write it into the repo folder as a real file\n","      os.makedirs(os.path.dirname(repo_ipynb_path), exist_ok=True)\n","      with open(repo_ipynb_path, \"w\", encoding=\"utf-8\") as f:\n","          json.dump(nb, f)\n","\n","      # convert + download pdf\n","      !jupyter nbconvert --to html \"{repo_ipynb_path}\"\n","      files.download(repo_ipynb_path.replace(\".ipynb\", \".html\"))\n","  except:\n","      import subprocess\n","\n","      nb_fp = os.getcwd() + f'{L}.ipynb'\n","      print(os.getcwd())\n","\n","      subprocess.run([\"jupyter\", \"nbconvert\", \"--to\", \"html\", nb_fp], check=True)\n","\n","#export_notebook()"],"metadata":{"id":"1HCtuuZFr_oT"},"execution_count":null,"outputs":[]}]}