{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNA7VaP46AKzeqC3EtCQLBL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-001.png\" class=\"img-responsive\"/>\n","</div>\n","\n"],"metadata":{"id":"EUZY_VNVJVKT"}},{"cell_type":"code","source":["def create_matrix(rows, cols):\n","    return [[0] * cols for r in range(rows)]\n","\n","print(create_matrix(2, 2))"],"metadata":{"id":"3Sj_A8jo8vbE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769529125450,"user_tz":300,"elapsed":2,"user":{"displayName":"William Theisen","userId":"17727777209816459717"}},"outputId":"3d59f9d4-e54a-4ec0-827f-ebe3d948ce07"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0, 0], [0, 0]]\n"]}]},{"cell_type":"markdown","source":["<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-002.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-003.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-004.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-005.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-007.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-008.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-006.png\" class=\"img-responsive\"/>\n","</div>"],"metadata":{"id":"mxAAF5GY8vxw"}},{"cell_type":"code","source":["from collections import Counter\n","\n","def _count_pairs(tokens):\n","    pair_counts = Counter()\n","\n","    for pair in zip(tokens, tokens[1:]):\n","        pair_counts[pair] += 1\n","\n","    return pair_counts\n","\n","def _merge_pair(tokens, target_pair, combined_id):\n","    merged_tokens = []\n","\n","    i = 0\n","    while i < len(tokens):\n","        if i < len(tokens) - 1 and (tokens[i], tokens[i+1]) == target_pair:\n","            merged_tokens.append(combined_id)\n","            i += 2\n","        else:\n","            merged_tokens.append(tokens[i])\n","            i += 1\n","\n","    return merged_tokens\n","\n","prompt = 'rug pug hug pun bun hugs run gun bug'\n","\n","string_bytes = list(prompt.encode('utf-8'))\n","print('String ASCII Values (bytes):', string_bytes)\n","\n","vocab = {idx: bytes([idx]) for idx in range(256)}\n","print('Initial Vocab:', vocab)"],"metadata":{"id":"YrVNrrXLU4_W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-009.png\" class=\"img-responsive\"/>\n","</div>"],"metadata":{"id":"Qjc4_fydVM2E"}},{"cell_type":"code","source":["class Cat():\n","    def __init__(self):\n","        pass"],"metadata":{"id":"hd7xo4cZVUUQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-010.png\" class=\"img-responsive\"/>\n","</div>"],"metadata":{"id":"jzaR-YvtVjIC"}},{"cell_type":"code","source":["\"\"\"\n","Minimal (byte-level) Byte Pair Encoding tokenizer.\n","\n","Algorithmically follows along the GPT tokenizer:\n","https://github.com/openai/gpt-2/blob/master/src/encoder.py\n","\"\"\"\n","\n","class Simple_Tokenizer():\n","    def __init__(self):\n","        self.merges = {} # (int, int) -> int\n","\n","        self.special_tokens = {'<|sos|>': 256, '<|eos|>': 257}\n","\n","        self.vocab = {idx: bytes([idx]) for idx in range(256)}\n","\n","        self.vocab[256] = '<|sos|>'\n","        self.vocab[257] = '<|eos|>'\n","\n","    def _count_pairs(self, ids, counts=None):\n","        pass\n","\n","    def _merge_pairs(self, ids, pair, idx):\n","        pass\n","\n","    def train(self, text, max_vocab_size):\n","        pass\n","\n","    def decode(self, ids):\n","        pass\n","\n","    def encode(self, text):\n","        pass"],"metadata":{"id":"BFd6HOBdVp2x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","try:\n","    import google.colab\n","    REPO_URL = \"https://github.com/wtheisen/nd-cse-10124-lectures.git\"\n","\n","    REPO_NAME = \"/content/nd-cse-10124-lectures\"\n","\n","    %cd /content/\n","    !rm -r {REPO_NAME}\n","\n","    # Clone repo\n","    if not os.path.exists(REPO_NAME):\n","        !git clone {REPO_URL}\n","\n","        # cd into the data folder\n","        %cd {REPO_NAME}\n","        !pwd\n","\n","except ImportError:\n","    print(\"Unable to download repo, either:\")\n","    print(\"\\tA.) You're not on colab\")\n","    print(\"\\tB.) It has already been cloned\")\n","\n","\n","import irishGPT.utilities as uts"],"metadata":{"id":"XauIb-liOtSM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769105000956,"user_tz":300,"elapsed":1639,"user":{"displayName":"William Theisen","userId":"17727777209816459717"}},"outputId":"acd9bc7e-a0be-4884-8406-7c9949428359"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'nd-cse-10124-lectures'...\n","remote: Enumerating objects: 230, done.\u001b[K\n","remote: Counting objects: 100% (230/230), done.\u001b[K\n","remote: Compressing objects: 100% (162/162), done.\u001b[K\n","remote: Total 230 (delta 145), reused 151 (delta 66), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (230/230), 19.88 MiB | 36.75 MiB/s, done.\n","Resolving deltas: 100% (145/145), done.\n","/content/nd-cse-10124-lectures/Datasets\n","/content/nd-cse-10124-lectures/Datasets\n"]}]},{"cell_type":"code","source":["#print('Size of Jabberwocky Graph (Tokens):', len(uts.create_token_graph('jabberwocky.txt')))\n","#print('Size of Shakespeare Graph (Tokens):', len(uts.create_token_graph('shakespeare.txt')))\n","# Size of Shakespeare Graph (Tokens): 286 (this takes like ~7 minutes to run)\n","\n","num_gens = 3\n","\n","char_graph = uts.build_graph_char('zoomer.txt')\n","print('Size of Zoomer Graph (Characters):', len(char_graph))\n","print('Character Level Generation [zoomer.txt]:')\n","for i in range(0, num_gens):\n","  print(f'\\t{i}: {''.join(uts.generate_sequence(char_graph, 50))}')\n","\n","print('#' * 80)\n","\n","for vocab_size in [258, 512, 1024, 2048, 4096]:\n","    s_t = Simple_Tokenizer()\n","\n","    token_graph = uts.build_graph_token('zoomer.txt', s_t, vocab_size=vocab_size)\n","    print('Size of Zoomer Graph (Tokens, No Regex):', len(token_graph))\n","\n","    print(f'Token Level Generation (No Regex, {vocab_size} Vocab Size) [zoomer.txt]:')\n","    for i in range(0, num_gens):\n","        print(f'\\t{i}: {''.join(uts.generate_sequence(token_graph, 50))}')\n","    print('#' * 80)\n","\n","word_graph = uts.build_graph_word('zoomer.txt', special_tokens=True)\n","print('Size of Zoomer Graph (Words):', len(word_graph))\n","print('Word Level Generation [zoomer.txt]:')\n","for i in range(0, num_gens):\n","  print(f'\\t{i}: {' '.join(uts.generate_sequence(word_graph, 50))}')\n"],"metadata":{"id":"-0aQhw4u1u0w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-011.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-012.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-013.png\" class=\"img-responsive\"/>\n","</div>"],"metadata":{"id":"qg5A-_onfRLz"}},{"cell_type":"code","source":["from irishGPT.tokenizer import RegexTokenizer\n","\n","r_t = RegexTokenizer()\n","\n","print(r_t.SPLIT_PATTERN)\n","\n","print(r_t.chunk(\"No cap are u rolling the party tonight?\"))\n","\n","for vocab_size in [512, 1024, 2048, 4096]:\n","    r_t = RegexTokenizer()\n","\n","    token_graph = uts.build_graph_token('zoomer.txt', r_t, vocab_size=vocab_size)\n","    print('#' * 80)\n","    print(f'''Size of Zoomer Graph (Tokens, Regex, {vocab_size} Vocab Size):', len(token_graph))\n","\n","Token Level Generation (Regex, {vocab_size} Vocab Size) [zoomer.txt]:''')\n","\n","    for i in range(0, num_gens):\n","        print(f'\\t{i}: {''.join(uts.generate_sequence(token_graph, 50))}')"],"metadata":{"id":"dv3sQu75KJyT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-015.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-014.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-016.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-017.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-018.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-019.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-020.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-021.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-022.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-023.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-024.png\" class=\"img-responsive\"/>\n","</div>\n","\n","<div class=\"thumbnail\">\n","    <img src=\"https://williamtheisen.com/nd-cse-10124-lectures/Lecture_Images/Lecture05/slide-025.png\" class=\"img-responsive\"/>\n","</div>"],"metadata":{"id":"Xs-8GO8-fZIp"}},{"cell_type":"markdown","source":["## Export to HTML\n","\n","Uncomment the final line of the cell below and run it to export this notebook to HTML"],"metadata":{"id":"xSLHa2zwsAlr"}},{"cell_type":"code","source":["import os, json\n","\n","def export_notebook():\n","  L_PATH = \"nd-cse-10124-lectures/Notebooks\"\n","  L = \"Lecture_05_Tokenization_03\"\n","\n","  try:\n","      from google.colab import _message, files\n","\n","      # where you WANT it to live (repo folder)\n","      repo_ipynb_path = f\"/content/{L_PATH}/{L}.ipynb\"\n","\n","      # grab current notebook contents from the UI\n","      nb = _message.blocking_request(\"get_ipynb\", timeout_sec=1)[\"ipynb\"]\n","\n","      # write it into the repo folder as a real file\n","      os.makedirs(os.path.dirname(repo_ipynb_path), exist_ok=True)\n","      with open(repo_ipynb_path, \"w\", encoding=\"utf-8\") as f:\n","          json.dump(nb, f)\n","\n","      # convert + download pdf\n","      !jupyter nbconvert --to html \"{repo_ipynb_path}\"\n","      files.download(repo_ipynb_path.replace(\".ipynb\", \".html\"))\n","  except:\n","      import subprocess\n","\n","      nb_fp = os.getcwd() + f'{L}.ipynb'\n","      print(os.getcwd())\n","\n","      subprocess.run([\"jupyter\", \"nbconvert\", \"--to\", \"html\", nb_fp], check=True)\n","\n","#export_notebook()"],"metadata":{"id":"1HCtuuZFr_oT"},"execution_count":null,"outputs":[]}]}